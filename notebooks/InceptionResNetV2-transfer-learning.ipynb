{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, GlobalAveragePooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "from tensorflow.keras.applications import VGG16, MobileNetV2, InceptionV3, InceptionResNetV2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from efficientnet import EfficientNetB3, center_crop_and_resize, preprocess_input\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import callbacks\n",
    "\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASEPATH = \"stanford-dogs-dataset/\"\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(patience=20, verbose=1,restore_best_weights=True, monitor=\"val_acc\")\n",
    "reduce_lr = ReduceLROnPlateau(factor=0.1, patience=7,verbose=1, monitor=\"val_acc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModelInceptionResNetV2(trainable=False, optimizer=\"adam\"):\n",
    "    base_model = InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(512,activation=\"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(120, activation=\"softmax\"))\n",
    "\n",
    "    if not trainable:\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy']) \n",
    "  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = createModelInceptionResNetV2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255.0,\n",
    "                                   shear_range=0.1,\n",
    "                                   rotation_range=10.,\n",
    "                                   width_shift_range=0.1,\n",
    "                                   height_shift_range=0.1,\n",
    "                                   zoom_range=[0.9, 1.25],\n",
    "                                   brightness_range=[0.5, 1.5],\n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255.0)\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15394 images belonging to 120 classes.\n",
      "Found 1114 images belonging to 120 classes.\n",
      "Found 4072 images belonging to 120 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    BASEPATH + \"train\",\n",
    "    target_size=(224, 224),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    BASEPATH + \"test\",\n",
    "    target_size=(224, 224),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    BASEPATH + \"val\",\n",
    "    target_size=(224, 224),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "64/64 [==============================] - 27s 425ms/step - loss: 0.8733 - acc: 0.8264\n",
      "241/241 [==============================] - 254s 1s/step - loss: 1.5238 - acc: 0.6104 - val_loss: 0.8733 - val_acc: 0.8264\n",
      "Epoch 2/100\n",
      "64/64 [==============================] - 26s 409ms/step - loss: 0.8456 - acc: 0.8310\n",
      "241/241 [==============================] - 242s 1s/step - loss: 1.4113 - acc: 0.6383 - val_loss: 0.8456 - val_acc: 0.8310\n",
      "Epoch 3/100\n",
      "64/64 [==============================] - 27s 415ms/step - loss: 0.8405 - acc: 0.8244\n",
      "241/241 [==============================] - 242s 1s/step - loss: 1.3687 - acc: 0.6430 - val_loss: 0.8405 - val_acc: 0.8244\n",
      "Epoch 4/100\n",
      "64/64 [==============================] - 27s 418ms/step - loss: 0.8692 - acc: 0.8269\n",
      "241/241 [==============================] - 244s 1s/step - loss: 1.3135 - acc: 0.6468 - val_loss: 0.8692 - val_acc: 0.8269\n",
      "Epoch 5/100\n",
      "64/64 [==============================] - 26s 414ms/step - loss: 0.8827 - acc: 0.8200\n",
      "241/241 [==============================] - 242s 1s/step - loss: 1.2875 - acc: 0.6559 - val_loss: 0.8827 - val_acc: 0.8200\n",
      "Epoch 6/100\n",
      "64/64 [==============================] - 26s 412ms/step - loss: 0.8302 - acc: 0.8183\n",
      "241/241 [==============================] - 242s 1s/step - loss: 1.2329 - acc: 0.6690 - val_loss: 0.8302 - val_acc: 0.8183\n",
      "Epoch 7/100\n",
      "64/64 [==============================] - 26s 413ms/step - loss: 0.8741 - acc: 0.8254\n",
      "241/241 [==============================] - 243s 1s/step - loss: 1.2255 - acc: 0.6668 - val_loss: 0.8741 - val_acc: 0.8254\n",
      "Epoch 8/100\n",
      "64/64 [==============================] - 26s 414ms/step - loss: 0.8527 - acc: 0.8195\n",
      "241/241 [==============================] - 243s 1s/step - loss: 1.1972 - acc: 0.6723 - val_loss: 0.8527 - val_acc: 0.8195\n",
      "Epoch 9/100\n",
      "64/64 [==============================] - 26s 414ms/step - loss: 0.8843 - acc: 0.8210\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "241/241 [==============================] - 243s 1s/step - loss: 1.1851 - acc: 0.6703 - val_loss: 0.8843 - val_acc: 0.8210\n",
      "Epoch 10/100\n",
      "64/64 [==============================] - 27s 415ms/step - loss: 0.8383 - acc: 0.8313\n",
      "241/241 [==============================] - 244s 1s/step - loss: 1.0557 - acc: 0.7075 - val_loss: 0.8383 - val_acc: 0.8313\n",
      "Epoch 11/100\n",
      "64/64 [==============================] - 27s 421ms/step - loss: 0.8552 - acc: 0.8306\n",
      "241/241 [==============================] - 243s 1s/step - loss: 1.0082 - acc: 0.7209 - val_loss: 0.8552 - val_acc: 0.8306\n",
      "Epoch 12/100\n",
      "64/64 [==============================] - 26s 414ms/step - loss: 0.8602 - acc: 0.8293\n",
      "241/241 [==============================] - 243s 1s/step - loss: 1.0066 - acc: 0.7189 - val_loss: 0.8602 - val_acc: 0.8293\n",
      "Epoch 13/100\n",
      "64/64 [==============================] - 27s 415ms/step - loss: 0.8429 - acc: 0.8328\n",
      "241/241 [==============================] - 244s 1s/step - loss: 0.9778 - acc: 0.7240 - val_loss: 0.8429 - val_acc: 0.8328\n",
      "Epoch 14/100\n",
      "64/64 [==============================] - 26s 411ms/step - loss: 0.8438 - acc: 0.8323\n",
      "241/241 [==============================] - 243s 1s/step - loss: 0.9680 - acc: 0.7259 - val_loss: 0.8438 - val_acc: 0.8323\n",
      "Epoch 15/100\n",
      "64/64 [==============================] - 27s 418ms/step - loss: 0.8492 - acc: 0.8333\n",
      "241/241 [==============================] - 243s 1s/step - loss: 0.9639 - acc: 0.7275 - val_loss: 0.8492 - val_acc: 0.8333\n",
      "Epoch 16/100\n",
      "64/64 [==============================] - 27s 424ms/step - loss: 0.8309 - acc: 0.8308\n",
      "241/241 [==============================] - 243s 1s/step - loss: 0.9783 - acc: 0.7242 - val_loss: 0.8309 - val_acc: 0.8308\n",
      "Epoch 17/100\n",
      "64/64 [==============================] - 27s 418ms/step - loss: 0.8329 - acc: 0.8337\n",
      "241/241 [==============================] - 244s 1s/step - loss: 0.9462 - acc: 0.7292 - val_loss: 0.8329 - val_acc: 0.8337\n",
      "Epoch 18/100\n",
      "64/64 [==============================] - 27s 420ms/step - loss: 0.8320 - acc: 0.8325\n",
      "241/241 [==============================] - 244s 1s/step - loss: 0.9554 - acc: 0.7284 - val_loss: 0.8320 - val_acc: 0.8325\n",
      "Epoch 19/100\n",
      "64/64 [==============================] - 26s 409ms/step - loss: 0.8401 - acc: 0.8315\n",
      "241/241 [==============================] - 242s 1s/step - loss: 0.9438 - acc: 0.7350 - val_loss: 0.8401 - val_acc: 0.8315\n",
      "Epoch 20/100\n",
      "64/64 [==============================] - 27s 419ms/step - loss: 0.8414 - acc: 0.8310\n",
      "241/241 [==============================] - 243s 1s/step - loss: 0.9404 - acc: 0.7328 - val_loss: 0.8414 - val_acc: 0.8310\n",
      "Epoch 21/100\n",
      "64/64 [==============================] - 26s 414ms/step - loss: 0.8347 - acc: 0.8320\n",
      "241/241 [==============================] - 243s 1s/step - loss: 0.9312 - acc: 0.7356 - val_loss: 0.8347 - val_acc: 0.8320\n",
      "Epoch 22/100\n",
      "64/64 [==============================] - 27s 415ms/step - loss: 0.8374 - acc: 0.8320\n",
      "241/241 [==============================] - 243s 1s/step - loss: 0.9182 - acc: 0.7369 - val_loss: 0.8374 - val_acc: 0.8320\n",
      "Epoch 23/100\n",
      "64/64 [==============================] - 26s 411ms/step - loss: 0.8301 - acc: 0.8315\n",
      "241/241 [==============================] - 243s 1s/step - loss: 0.9219 - acc: 0.7381 - val_loss: 0.8301 - val_acc: 0.8315\n",
      "Epoch 24/100\n",
      "64/64 [==============================] - 27s 417ms/step - loss: 0.8244 - acc: 0.8308\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "241/241 [==============================] - 243s 1s/step - loss: 0.9149 - acc: 0.7380 - val_loss: 0.8244 - val_acc: 0.8308\n",
      "Epoch 25/100\n",
      "64/64 [==============================] - 26s 410ms/step - loss: 0.8249 - acc: 0.8306\n",
      "241/241 [==============================] - 244s 1s/step - loss: 0.9048 - acc: 0.7407 - val_loss: 0.8249 - val_acc: 0.8306\n",
      "Epoch 26/100\n",
      "64/64 [==============================] - 27s 419ms/step - loss: 0.8242 - acc: 0.8296\n",
      "241/241 [==============================] - 243s 1s/step - loss: 0.9067 - acc: 0.7413 - val_loss: 0.8242 - val_acc: 0.8296\n",
      "Epoch 27/100\n",
      "64/64 [==============================] - 27s 420ms/step - loss: 0.8241 - acc: 0.8301\n",
      "241/241 [==============================] - 243s 1s/step - loss: 0.8960 - acc: 0.7402 - val_loss: 0.8241 - val_acc: 0.8301\n",
      "Epoch 28/100\n",
      "64/64 [==============================] - 27s 419ms/step - loss: 0.8272 - acc: 0.8303\n",
      "241/241 [==============================] - 243s 1s/step - loss: 0.8895 - acc: 0.7435 - val_loss: 0.8272 - val_acc: 0.8303\n",
      "Epoch 29/100\n",
      "64/64 [==============================] - 27s 422ms/step - loss: 0.8231 - acc: 0.8318\n",
      "241/241 [==============================] - 243s 1s/step - loss: 0.9075 - acc: 0.7389 - val_loss: 0.8231 - val_acc: 0.8318\n",
      "Epoch 30/100\n",
      "64/64 [==============================] - 27s 422ms/step - loss: 0.8250 - acc: 0.8310\n",
      "241/241 [==============================] - 243s 1s/step - loss: 0.8990 - acc: 0.7407 - val_loss: 0.8250 - val_acc: 0.8310\n",
      "Epoch 31/100\n",
      "64/64 [==============================] - 27s 420ms/step - loss: 0.8224 - acc: 0.8315\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "241/241 [==============================] - 245s 1s/step - loss: 0.8924 - acc: 0.7435 - val_loss: 0.8224 - val_acc: 0.8315\n",
      "Epoch 32/100\n",
      "64/64 [==============================] - 27s 415ms/step - loss: 0.8271 - acc: 0.8318\n",
      "241/241 [==============================] - 242s 1s/step - loss: 0.8836 - acc: 0.7455 - val_loss: 0.8271 - val_acc: 0.8318\n",
      "Epoch 33/100\n",
      "64/64 [==============================] - 27s 422ms/step - loss: 0.8235 - acc: 0.8318\n",
      "241/241 [==============================] - 243s 1s/step - loss: 0.8859 - acc: 0.7446 - val_loss: 0.8235 - val_acc: 0.8318\n",
      "Epoch 34/100\n",
      "64/64 [==============================] - 26s 410ms/step - loss: 0.8254 - acc: 0.8318\n",
      "241/241 [==============================] - 243s 1s/step - loss: 0.8881 - acc: 0.7430 - val_loss: 0.8254 - val_acc: 0.8318\n",
      "Epoch 35/100\n",
      "64/64 [==============================] - 27s 417ms/step - loss: 0.8306 - acc: 0.8313\n",
      "241/241 [==============================] - 243s 1s/step - loss: 0.8921 - acc: 0.7463 - val_loss: 0.8306 - val_acc: 0.8313\n",
      "Epoch 36/100\n",
      "64/64 [==============================] - 26s 408ms/step - loss: 0.8247 - acc: 0.8315\n",
      "241/241 [==============================] - 242s 1s/step - loss: 0.8933 - acc: 0.7410 - val_loss: 0.8247 - val_acc: 0.8315\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 27s 418ms/step - loss: 0.8248 - acc: 0.8318\n",
      "Restoring model weights from the end of the best epoch.\n",
      "241/241 [==============================] - 246s 1s/step - loss: 0.8977 - acc: 0.7417 - val_loss: 0.8248 - val_acc: 0.8318\n",
      "Epoch 00037: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f16b0c57390>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = train_generator.samples // BATCH_SIZE,\n",
    "    validation_data = validation_generator, \n",
    "    validation_steps = validation_generator.samples // BATCH_SIZE,\n",
    "    epochs = EPOCHS, callbacks=[early_stopping, reduce_lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate_generator(test_generator,verbose=0, steps=test_generator.samples // BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8152329872051874 0.8330341\n"
     ]
    }
   ],
   "source": [
    "print(loss,acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"inceptionv3-model-{:.2f}acc-{:.2f}loss-{:.0f}.hdf5\".format(acc, loss, time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
