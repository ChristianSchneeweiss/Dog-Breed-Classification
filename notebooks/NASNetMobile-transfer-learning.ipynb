{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, GlobalAveragePooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "from tensorflow.keras.applications import VGG16, MobileNetV2, InceptionV3, NASNetLarge, NASNetMobile\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from efficientnet import EfficientNetB3, center_crop_and_resize, preprocess_input\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import callbacks\n",
    "\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASEPATH = \"stanford-dogs-dataset/\"\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(patience=20, verbose=1,restore_best_weights=True, monitor=\"val_acc\")\n",
    "reduce_lr = ReduceLROnPlateau(factor=0.1, patience=7,verbose=1, monitor=\"val_acc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModelNASNetMobile(trainable=False, optimizer=\"adam\"):\n",
    "    base_model = NASNetMobile(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(512,activation=\"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(120, activation=\"softmax\"))\n",
    "    \n",
    "    if not trainable:\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy']) \n",
    "  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = createModelNASNetMobile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255.0,\n",
    "                                   shear_range=0.1,\n",
    "                                   rotation_range=10.,\n",
    "                                   width_shift_range=0.1,\n",
    "                                   height_shift_range=0.1,\n",
    "                                   zoom_range=[0.9, 1.1],\n",
    "                                   brightness_range=[0.8, 1.2],\n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255.0)\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15394 images belonging to 120 classes.\n",
      "Found 1114 images belonging to 120 classes.\n",
      "Found 4072 images belonging to 120 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    BASEPATH + \"train\",\n",
    "    target_size=(224, 224),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    BASEPATH + \"test\",\n",
    "    target_size=(224, 224),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    BASEPATH + \"val\",\n",
    "    target_size=(224, 224),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "64/64 [==============================] - 27s 428ms/step - loss: 0.6446 - acc: 0.8067\n",
      "241/241 [==============================] - 246s 1s/step - loss: 1.8795 - acc: 0.5542 - val_loss: 0.6446 - val_acc: 0.8067\n",
      "Epoch 2/100\n",
      "64/64 [==============================] - 27s 420ms/step - loss: 0.6536 - acc: 0.7974\n",
      "241/241 [==============================] - 239s 990ms/step - loss: 1.1508 - acc: 0.6827 - val_loss: 0.6536 - val_acc: 0.7974\n",
      "Epoch 3/100\n",
      "64/64 [==============================] - 26s 411ms/step - loss: 0.6464 - acc: 0.8057\n",
      "241/241 [==============================] - 239s 993ms/step - loss: 1.0748 - acc: 0.6943 - val_loss: 0.6464 - val_acc: 0.8057\n",
      "Epoch 4/100\n",
      "64/64 [==============================] - 26s 408ms/step - loss: 0.6446 - acc: 0.8033\n",
      "241/241 [==============================] - 239s 993ms/step - loss: 1.0130 - acc: 0.7133 - val_loss: 0.6446 - val_acc: 0.8033\n",
      "Epoch 5/100\n",
      "64/64 [==============================] - 26s 408ms/step - loss: 0.6393 - acc: 0.8060\n",
      "241/241 [==============================] - 239s 990ms/step - loss: 0.9643 - acc: 0.7237 - val_loss: 0.6393 - val_acc: 0.8060\n",
      "Epoch 6/100\n",
      "64/64 [==============================] - 26s 408ms/step - loss: 0.6449 - acc: 0.8134\n",
      "241/241 [==============================] - 239s 991ms/step - loss: 0.9215 - acc: 0.7346 - val_loss: 0.6449 - val_acc: 0.8134\n",
      "Epoch 7/100\n",
      "64/64 [==============================] - 26s 410ms/step - loss: 0.6502 - acc: 0.8030\n",
      "241/241 [==============================] - 239s 990ms/step - loss: 0.9176 - acc: 0.7305 - val_loss: 0.6502 - val_acc: 0.8030\n",
      "Epoch 8/100\n",
      "64/64 [==============================] - 26s 400ms/step - loss: 0.6661 - acc: 0.8026\n",
      "241/241 [==============================] - 239s 990ms/step - loss: 0.8869 - acc: 0.7363 - val_loss: 0.6661 - val_acc: 0.8026\n",
      "Epoch 9/100\n",
      "64/64 [==============================] - 26s 411ms/step - loss: 0.6499 - acc: 0.8043\n",
      "241/241 [==============================] - 239s 993ms/step - loss: 0.8532 - acc: 0.7467 - val_loss: 0.6499 - val_acc: 0.8043\n",
      "Epoch 10/100\n",
      "64/64 [==============================] - 26s 407ms/step - loss: 0.6894 - acc: 0.8008\n",
      "241/241 [==============================] - 238s 987ms/step - loss: 0.8389 - acc: 0.7496 - val_loss: 0.6894 - val_acc: 0.8008\n",
      "Epoch 11/100\n",
      "64/64 [==============================] - 26s 406ms/step - loss: 0.6700 - acc: 0.8048\n",
      "241/241 [==============================] - 239s 990ms/step - loss: 0.8312 - acc: 0.7540 - val_loss: 0.6700 - val_acc: 0.8048\n",
      "Epoch 12/100\n",
      "64/64 [==============================] - 26s 407ms/step - loss: 0.6828 - acc: 0.8053\n",
      "241/241 [==============================] - 239s 992ms/step - loss: 0.8008 - acc: 0.7564 - val_loss: 0.6828 - val_acc: 0.8053\n",
      "Epoch 13/100\n",
      "64/64 [==============================] - 26s 411ms/step - loss: 0.6675 - acc: 0.8043\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "241/241 [==============================] - 241s 998ms/step - loss: 0.7960 - acc: 0.7602 - val_loss: 0.6675 - val_acc: 0.8043\n",
      "Epoch 14/100\n",
      "64/64 [==============================] - 26s 413ms/step - loss: 0.6529 - acc: 0.8141\n",
      "241/241 [==============================] - 240s 996ms/step - loss: 0.7098 - acc: 0.7794 - val_loss: 0.6529 - val_acc: 0.8141\n",
      "Epoch 15/100\n",
      "64/64 [==============================] - 26s 412ms/step - loss: 0.6498 - acc: 0.8151\n",
      "241/241 [==============================] - 240s 995ms/step - loss: 0.6681 - acc: 0.7918 - val_loss: 0.6498 - val_acc: 0.8151\n",
      "Epoch 16/100\n",
      "64/64 [==============================] - 26s 408ms/step - loss: 0.6574 - acc: 0.8124\n",
      "241/241 [==============================] - 240s 994ms/step - loss: 0.6532 - acc: 0.7970 - val_loss: 0.6574 - val_acc: 0.8124\n",
      "Epoch 17/100\n",
      "64/64 [==============================] - 27s 416ms/step - loss: 0.6561 - acc: 0.8111\n",
      "241/241 [==============================] - 240s 996ms/step - loss: 0.6310 - acc: 0.8003 - val_loss: 0.6561 - val_acc: 0.8111\n",
      "Epoch 18/100\n",
      "64/64 [==============================] - 26s 414ms/step - loss: 0.6521 - acc: 0.8114\n",
      "241/241 [==============================] - 240s 994ms/step - loss: 0.6361 - acc: 0.8027 - val_loss: 0.6521 - val_acc: 0.8114\n",
      "Epoch 19/100\n",
      "64/64 [==============================] - 26s 407ms/step - loss: 0.6520 - acc: 0.8146\n",
      "241/241 [==============================] - 239s 993ms/step - loss: 0.6310 - acc: 0.8060 - val_loss: 0.6520 - val_acc: 0.8146\n",
      "Epoch 20/100\n",
      "64/64 [==============================] - 26s 413ms/step - loss: 0.6519 - acc: 0.8143\n",
      "241/241 [==============================] - 239s 992ms/step - loss: 0.6301 - acc: 0.8009 - val_loss: 0.6519 - val_acc: 0.8143\n",
      "Epoch 21/100\n",
      "64/64 [==============================] - 26s 413ms/step - loss: 0.6529 - acc: 0.8121\n",
      "241/241 [==============================] - 240s 996ms/step - loss: 0.6214 - acc: 0.8060 - val_loss: 0.6529 - val_acc: 0.8121\n",
      "Epoch 22/100\n",
      "64/64 [==============================] - 26s 407ms/step - loss: 0.6500 - acc: 0.8131\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "241/241 [==============================] - 239s 992ms/step - loss: 0.6142 - acc: 0.8062 - val_loss: 0.6500 - val_acc: 0.8131\n",
      "Epoch 23/100\n",
      "64/64 [==============================] - 26s 408ms/step - loss: 0.6536 - acc: 0.8136\n",
      "241/241 [==============================] - 239s 993ms/step - loss: 0.5968 - acc: 0.8113 - val_loss: 0.6536 - val_acc: 0.8136\n",
      "Epoch 24/100\n",
      "64/64 [==============================] - 26s 406ms/step - loss: 0.6529 - acc: 0.8139\n",
      "241/241 [==============================] - 240s 994ms/step - loss: 0.6128 - acc: 0.8052 - val_loss: 0.6529 - val_acc: 0.8139\n",
      "Epoch 25/100\n",
      "64/64 [==============================] - 26s 413ms/step - loss: 0.6517 - acc: 0.8139\n",
      "241/241 [==============================] - 240s 998ms/step - loss: 0.5971 - acc: 0.8103 - val_loss: 0.6517 - val_acc: 0.8139\n",
      "Epoch 26/100\n",
      "64/64 [==============================] - 26s 409ms/step - loss: 0.6515 - acc: 0.8136\n",
      "241/241 [==============================] - 240s 995ms/step - loss: 0.5978 - acc: 0.8140 - val_loss: 0.6515 - val_acc: 0.8136\n",
      "Epoch 27/100\n",
      "64/64 [==============================] - 26s 411ms/step - loss: 0.6529 - acc: 0.8134\n",
      "241/241 [==============================] - 239s 991ms/step - loss: 0.5921 - acc: 0.8125 - val_loss: 0.6529 - val_acc: 0.8134\n",
      "Epoch 28/100\n",
      "64/64 [==============================] - 26s 408ms/step - loss: 0.6498 - acc: 0.8139\n",
      "241/241 [==============================] - 239s 991ms/step - loss: 0.5955 - acc: 0.8141 - val_loss: 0.6498 - val_acc: 0.8139\n",
      "Epoch 29/100\n",
      "64/64 [==============================] - 26s 409ms/step - loss: 0.6507 - acc: 0.8141\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "241/241 [==============================] - 239s 990ms/step - loss: 0.6000 - acc: 0.8089 - val_loss: 0.6507 - val_acc: 0.8141\n",
      "Epoch 30/100\n",
      "64/64 [==============================] - 26s 405ms/step - loss: 0.6513 - acc: 0.8141\n",
      "241/241 [==============================] - 239s 992ms/step - loss: 0.5924 - acc: 0.8123 - val_loss: 0.6513 - val_acc: 0.8141\n",
      "Epoch 31/100\n",
      "64/64 [==============================] - 26s 409ms/step - loss: 0.6500 - acc: 0.8134\n",
      "241/241 [==============================] - 239s 993ms/step - loss: 0.5966 - acc: 0.8130 - val_loss: 0.6500 - val_acc: 0.8134\n",
      "Epoch 32/100\n",
      "64/64 [==============================] - 26s 408ms/step - loss: 0.6522 - acc: 0.8136\n",
      "241/241 [==============================] - 240s 994ms/step - loss: 0.5982 - acc: 0.8099 - val_loss: 0.6522 - val_acc: 0.8136\n",
      "Epoch 33/100\n",
      "64/64 [==============================] - 26s 407ms/step - loss: 0.6509 - acc: 0.8136\n",
      "241/241 [==============================] - 240s 996ms/step - loss: 0.5955 - acc: 0.8121 - val_loss: 0.6509 - val_acc: 0.8136\n",
      "Epoch 34/100\n",
      "64/64 [==============================] - 26s 409ms/step - loss: 0.6518 - acc: 0.8134\n",
      "241/241 [==============================] - 239s 992ms/step - loss: 0.5997 - acc: 0.8094 - val_loss: 0.6518 - val_acc: 0.8134\n",
      "Epoch 35/100\n",
      "64/64 [==============================] - 26s 409ms/step - loss: 0.6498 - acc: 0.8139\n",
      "Restoring model weights from the end of the best epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241/241 [==============================] - 243s 1s/step - loss: 0.6025 - acc: 0.8111 - val_loss: 0.6498 - val_acc: 0.8139\n",
      "Epoch 00035: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2c68d4c7b8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = train_generator.samples // BATCH_SIZE,\n",
    "    validation_data = validation_generator, \n",
    "    validation_steps = validation_generator.samples // BATCH_SIZE,\n",
    "    epochs = EPOCHS, callbacks=[early_stopping, reduce_lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate_generator(test_generator,verbose=0, steps=test_generator.samples // BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6951451136006249 0.8105925\n"
     ]
    }
   ],
   "source": [
    "print(loss,acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"nasnetlarge-model-{:.2f}acc-{:.2f}loss-{:.0f}.hdf5\".format(acc, loss, time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
